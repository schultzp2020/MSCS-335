{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "\n",
    "Y_columns = ['koi_disposition', 'koi_pdisposition', 'koi_score']\n",
    "misc_columns = ['kepid', 'kepoi_name', 'kepler_name', 'koi_tce_delivname']\n",
    "\n",
    "train_X = train_df.drop(columns=Y_columns + misc_columns)\n",
    "train_Y = train_df[Y_columns + misc_columns]\n",
    "\n",
    "test_X = test_df.drop(columns=Y_columns + misc_columns)\n",
    "test_Y = test_df[Y_columns + misc_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "les = {}\n",
    "Y = pd.concat([train_Y, test_Y])\n",
    "for dtype, col in zip(Y.dtypes, Y.columns):\n",
    "  if dtype == 'object':\n",
    "    les[col] = LabelEncoder()\n",
    "    les[col].fit(Y[col])\n",
    "    train_Y[col] = les[col].transform(train_Y[col])\n",
    "    test_Y[col] = les[col].transform(test_Y[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(train_X)\n",
    "count = 0\n",
    "for s in pca.singular_values_:\n",
    "    if s/pca.singular_values_[0] > 0.01:\n",
    "        count += 1\n",
    "pca_trans = PCA(n_components=count)\n",
    "pca_trans.fit(train_X)\n",
    "trans_train_X = pca_trans.transform(train_X)\n",
    "trans_test_X = pca_trans.transform(test_X)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.37258464653720563\n",
      "0.11525590394899117\n",
      "0.06369390705845548\n",
      "0.003937521975756601\n",
      "0.0030938744477864264\n",
      "0.002745615177389313\n",
      "0.0018206059996874271\n",
      "0.0015351272795401855\n",
      "0.0003828646357052927\n",
      "0.0003043074615647158\n",
      "0.00017377962283244227\n",
      "0.00012722143147526796\n",
      "9.69638877383647e-05\n",
      "4.967380765021818e-05\n",
      "4.1999033105870064e-05\n",
      "2.4923067169129242e-05\n",
      "2.097955691357579e-05\n",
      "1.607633104227409e-05\n",
      "1.3785447770786843e-05\n",
      "5.040022270275944e-06\n",
      "3.1235082582259057e-06\n",
      "2.8211103367709467e-06\n",
      "2.3880735124608076e-06\n",
      "1.9380300823707857e-06\n",
      "1.8638722539147122e-06\n",
      "1.7356892245824735e-06\n",
      "1.440219541249027e-06\n",
      "1.3462717018573192e-06\n",
      "1.1057498268864805e-06\n",
      "1.0604167795667362e-06\n",
      "8.766701949831546e-07\n",
      "3.865120058778914e-07\n",
      "2.253968743853631e-07\n",
      "1.0644558978175047e-07\n",
      "2.20229044118726e-08\n",
      "6.729891365778897e-17\n",
      "6.729891365778897e-17\n",
      "6.729891365778897e-17\n",
      "6.729891365778897e-17\n"
     ]
    }
   ],
   "source": [
    "for s in pca.singular_values_:\n",
    "  print(s/pca.singular_values_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "At first glance it seems like PCA can be used to cut down the columns to a smaller dimension because most columns do not seem important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KOI Score - Disposition Score | With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: -0.1885149144241418\n",
      "Score: -0.07327757838979743\n"
     ]
    }
   ],
   "source": [
    "m = DecisionTreeRegressor()\n",
    "cvs = cross_val_score(m, trans_train_X, train_Y['koi_score'], cv=5)\n",
    "m.fit(trans_train_X, train_Y['koi_score'])\n",
    "score = m.score(trans_test_X, test_Y['koi_score'])\n",
    "print(f'Cross Validation Score: {cvs.min()}\\nScore: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.2787715146863131\n",
      "Score: 0.2867274295892964\n"
     ]
    }
   ],
   "source": [
    "m = KNeighborsRegressor()\n",
    "cvs = cross_val_score(m, trans_train_X, train_Y['koi_score'], cv=5)\n",
    "m.fit(trans_train_X, train_Y['koi_score'])\n",
    "score = m.score(trans_test_X, test_Y['koi_score'])\n",
    "print(f'Cross Validation Score: {cvs.min()}\\nScore: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.36707725043203965\n",
      "Score: 0.3961136896596815\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor()\n",
    "cvs = cross_val_score(m, trans_train_X, train_Y['koi_score'], cv=5)\n",
    "m.fit(trans_train_X, train_Y['koi_score'])\n",
    "score = m.score(trans_test_X, test_Y['koi_score'])\n",
    "print(f'Cross Validation Score: {cvs.min()}\\nScore: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Using PCA hurts every regressor's score because every data point is extremely important in determining whether a potential exoplanet is indeed an exoplanet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KOI Score - Disposition Score | Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.8954566034912395\n",
      "Score: 0.8982989627431021\n"
     ]
    }
   ],
   "source": [
    "m = DecisionTreeRegressor()\n",
    "cvs = cross_val_score(m, train_X, train_Y['koi_score'], cv=5)\n",
    "m.fit(train_X, train_Y['koi_score'])\n",
    "score = m.score(test_X, test_Y['koi_score'])\n",
    "print(f'Cross Validation Score: {cvs.min()}\\nScore: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.3433131477492969\n",
      "Score: 0.379687033794619\n"
     ]
    }
   ],
   "source": [
    "m = KNeighborsRegressor()\n",
    "cvs = cross_val_score(m, train_X, train_Y['koi_score'], cv=5)\n",
    "m.fit(train_X, train_Y['koi_score'])\n",
    "score = m.score(test_X, test_Y['koi_score'])\n",
    "print(f'Cross Validation Score: {cvs.min()}\\nScore: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.9433921490761643\n",
      "Score: 0.9559849071249745\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor()\n",
    "cvs = cross_val_score(m, train_X, train_Y['koi_score'], cv=5)\n",
    "m.fit(train_X, train_Y['koi_score'])\n",
    "score = m.score(test_X, test_Y['koi_score'])\n",
    "print(f'Cross Validation Score: {cvs.min()}\\nScore: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The random forest regressor, like the classifier, is unsurprisingly the best regressor to predict KOI score. It does make sense that the decision tree regressor is the second best regressor because the koi score is an amalgamation of predictors which directly relates to classification through a tree like structure. Lastly, like the classifier, the k nearest neighbor regressor was expected to perform poorly because there are so many dimensions and its hard to get a notion of \"nearest.\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38f45ac4d2b9ff5c831db3abb6f1cdadc25a2cdb76c4e25ba448cd167b5637e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('MSCS-basic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
